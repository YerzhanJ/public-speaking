{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winton Kafka Streams\n",
    "\n",
    "    sudo pip3 install git+https://github.com/wintoncode/winton-kafka-streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/mario/git/winton-kafka-streams/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "from winton_kafka_streams.processor import BaseProcessor, TopologyBuilder\n",
    "from winton_kafka_streams.state.simple import SimpleStore\n",
    "import winton_kafka_streams.kafka_config as kafka_config\n",
    "import winton_kafka_streams.kafka_streams as kafka_streams\n",
    "import winton_kafka_streams.state as kafka_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_events_topic = 'car'\n",
    "weather_topic = 'weather'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "kafka_config.AUTO_OFFSET_RESET = 'latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class ReadJson(BaseProcessor):\n",
    "    def process(self, key, value):\n",
    "        self.context.forward(key, json.loads(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather state management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateState(BaseProcessor):\n",
    "    def initialise(self, name, context):\n",
    "        super(UpdateState, self).initialise(name, context)\n",
    "        self.store = context.get_store('weather_store')\n",
    "    \n",
    "    def process(self, key, value):\n",
    "        self.store.update_weather(key.decode('ascii'), value)\n",
    "         \n",
    "class WeatherStore:\n",
    "    def __init__(self, name):\n",
    "        self.data = {}\n",
    "        \n",
    "    def update_weather(self, station, results):\n",
    "        self.data[station] = results\n",
    "        logging.debug(f\"Weather info for {station} updated (got {len(self.data)} so far)!\")\n",
    "        \n",
    "    def initialized(self):\n",
    "        return len(self.data) > 0\n",
    "        \n",
    "    def get_current(self):\n",
    "        return pd.DataFrame(list(self.data.values())).set_index('station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars events processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessLoopEvent(BaseProcessor):\n",
    "    def initialise(self, name, context):\n",
    "        super(ProcessLoopEvent, self).initialise(name, context)\n",
    "        self.context.schedule(1)\n",
    "        self.datastore = deque(maxlen=10)\n",
    "        self.datastore.append([])\n",
    "        \n",
    "    def punctuate(self, timestamp):\n",
    "        small = self.datastore[-1]\n",
    "        large = [item for sublist in self.datastore for item in sublist]\n",
    "        self.context.forward(None, json.dumps({'1s': small, '10s': large}))\n",
    "        self.datastore.append([])\n",
    "    \n",
    "    def process(self, key, value):\n",
    "        self.datastore[-1].append(value)\n",
    "                \n",
    "class CalculateStatsAndJoin(BaseProcessor):\n",
    "    def stats(self, df, label):\n",
    "        result = df.groupby('point_id').agg({'speed': ['mean', 'count'], 'gap_meters': ['mean', 'min']})\n",
    "        result.columns = ['%d_%s' % (label, stat) for stat in ['avg_speed', 'num_cars', 'avg_gap', 'min_gap']]\n",
    "        return result\n",
    "\n",
    "    def compute_model(self, small, large):\n",
    "        if len(small) == 0 or len(large) == 0:\n",
    "            return \"empty loop windows\"\n",
    "        \n",
    "        if not self.context.get_store('weather_store').initialized():\n",
    "            return \"initializing\"\n",
    "        \n",
    "        one_minute_stats = self.stats(pd.DataFrame(small), 1)\n",
    "        ten_minutes_stats = self.stats(pd.DataFrame(large), 10)\n",
    "        joined_windows = ten_minutes_stats.join(one_minute_stats, how='left')\n",
    "        points_db = pd.read_csv('/home/mario/pydata2017/generator/road_points.csv').set_index('point_id')\n",
    "        points_db['point_id'] = points_db.index\n",
    "        result = joined_windows.join(points_db).set_index('nearest_weather_station') \\\n",
    "            .join(self.context.get_store('weather_store').get_current()).set_index('point_id')\n",
    "\n",
    "        return result['10_num_cars'].to_dict()\n",
    "    \n",
    "    def process(self, key, value):\n",
    "        value = json.loads(value)\n",
    "        print(self.compute_model(value['1s'], value['10s']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build topology and stream!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TopologyBuilder() as topology_builder:\n",
    "        topology_builder. \\\n",
    "            source('loop-event-json', [car_events_topic]). \\\n",
    "            source('weather-event-json', [weather_topic]). \\\n",
    "            state_store('weather_store', WeatherStore, 'weather', 'stats') .\\\n",
    "            processor('weather-event', ReadJson, 'weather-event-json'). \\\n",
    "            processor('weather', UpdateState, 'weather-event'). \\\n",
    "            processor('loop-event', ReadJson, 'loop-event-json'). \\\n",
    "            processor('loops-windows', ProcessLoopEvent, 'loop-event'). \\\n",
    "            processor('stats', CalculateStatsAndJoin, 'loops-windows')\n",
    "\n",
    "wks = kafka_streams.KafkaStreams(topology_builder, kafka_config)\n",
    "wks.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wks.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
